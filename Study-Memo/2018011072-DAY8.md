## WEEK 8

#### 2018011072 无82班 王景维
### RNN
* 循环网络结构：训练目标（标签），损失函数（Loss），网络输出（Output），状态（隐藏单元），网络输入（Input）
* 在不同的时间步上采用相同的UVW权重矩阵，U：输入到隐藏的连接的参数化的权重矩阵。W：隐藏到隐藏的循环连接的参数化的权重矩阵。V：隐藏到输出的连接的参数化的权重矩阵
* loss处理：收集所有时刻的输出，计算loss，梯度截取，防止梯度爆炸

### LSTM
* 解决RNN梯度爆炸、梯度消失的问题
* 比RNN增加了一个辅助记忆单元和其它三个辅助的门限输入单元
* * 输入门，控制是否输入
* * 遗忘门：控制是否储存
* * 输出门：控制是否输出
* 记忆单元和门单元的组合，提升了RNN处理远距离依赖问题的能力 ，解决RNN网络收敛
慢的问题。

### Automatic Differetiation
* 前向微分
* 后向微分

* 阅读论文的作业，由于考试周时间太紧张，下一周的study memo里补上
